# Awaitter Lite

<div align="center">

**The AI coding assistant that NEVER loses track of your project**

[![npm version](https://img.shields.io/npm/v/awaitter-lite.svg)](https://www.npmjs.com/package/awaitter-lite)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Downloads](https://img.shields.io/npm/dm/awaitter-lite.svg)](https://www.npmjs.com/package/awaitter-lite)

Multi-model AI assistant with **automatic project planning**, **smart execution modes**, and **zero context loss**

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Roadmap System](#-roadmap-system-new) â€¢ [Commands](#-commands) â€¢ [Models](#-supported-models)

</div>

---

## âš¡ What's New in v1.0.35

<table>
<tr>
<td width="50%">

### ğŸ—ºï¸ **Smart Roadmap System**
Automatically breaks down complex projects into sprints and tasks. **Never loses track**, even on 100+ file projects.

</td>
<td width="50%">

### ğŸ® **3 Execution Modes**
Choose your style: Full auto, sprint-by-sprint, or step-by-step control.

</td>
</tr>
<tr>
<td width="50%">

### ğŸ”„ **Model Hot-Swapping**
Switch between GPT-4, Claude, Gemini mid-project. **Context preserved 100%**.

</td>
<td width="50%">

### âš¡ **Persistent Progress**
Close the CLI, reboot your PC. Your roadmap and progress stay intact.

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

```bash
# Install globally
npm install -g awaitter-lite

# Start coding
awaitter-lite
# or short alias
aw
```

**First time?** Run `/setup` for guided configuration.

---

## ğŸ¯ What Makes Awaitter Different?

Most AI assistants give up halfway through complex projects. **Awaitter Lite doesn't.**

### The Problem with Traditional AI Assistants

```
You: "Create a full-stack e-commerce app"
Traditional AI: "Here's App.tsx... [loses context]"
                "Oh, what were we doing?"
                âŒ 30% complete, then stops
```

### The Awaitter Approach

```
You: "Create a full-stack e-commerce app"
Awaitter:
  ğŸ“‹ Generates roadmap with 5 sprints, 23 tasks
  âš¡ Executes systematically
  âœ… Tracks progress: 23/23 tasks complete
  ğŸ‰ Full app delivered, tested, documented
```

---

## ğŸ—ºï¸ Roadmap System (NEW)

When you request something complex, Awaitter **automatically creates a structured roadmap**.

### Example: Full-Stack App Request

```bash
> Create a real-time order tracking system for B2B, multi-tenant
```

**Awaitter generates:**

```
ğŸ“‹ PROJECT ROADMAP: B2B Order Tracking System

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ—ï¸  SPRINT 1: DATABASE & CORE MODELS (Estimated: ~15 min)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜ 1.1  Create database schema (users, tenants, orders)
â˜ 1.2  Set up migrations and seed data
â˜ 1.3  Create SQLAlchemy models

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”  SPRINT 2: AUTHENTICATION & MULTI-TENANCY (~20 min)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜ 2.1  Implement JWT authentication
â˜ 2.2  Add tenant isolation middleware
â˜ 2.3  Create user management endpoints

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¦  SPRINT 3: ORDER MANAGEMENT API (~25 min)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜ 3.1  CRUD endpoints for orders
â˜ 3.2  Real-time WebSocket handlers
â˜ 3.3  Status update workflows

... and 2 more sprints

TOTAL: 23 tasks | 5 sprints | ~85 minutes estimated
```

**Then it executes systematically:**

```
âœ… SPRINT 1: DATABASE & CORE MODELS - COMPLETED (12 tasks)
âœ… SPRINT 2: AUTHENTICATION & MULTI-TENANCY - COMPLETED (8 tasks)
â³ SPRINT 3: ORDER MANAGEMENT API - IN PROGRESS (3/5 tasks)
â˜ SPRINT 4: FRONTEND & UI
â˜ SPRINT 5: TESTING & DEPLOYMENT
```

---

## ğŸ® Execution Modes

Choose how Awaitter works for you:

<table>
<tr>
<th>Mode</th>
<th>Best For</th>
<th>How It Works</th>
</tr>
<tr>
<td>

**ğŸš€ Unstoppable**

</td>
<td>Fast devs who want results NOW</td>
<td>

Executes entire roadmap automatically. Only stops for critical errors.

</td>
</tr>
<tr>
<td>

**ğŸƒ Sprint** â­ *Default*

</td>
<td>Balanced control & speed</td>
<td>

Completes one sprint, shows summary, waits for your "continue".

</td>
</tr>
<tr>
<td>

**ğŸ‘£ Step-by-Step**

</td>
<td>Learning, reviewing, precision work</td>
<td>

Executes one task, pauses. You approve each step.

</td>
</tr>
</table>

**Change anytime:** `/mode unstoppable` or `/mode step-by-step`

### Visual Example

```bash
# Sprint Mode (Default)
âœ… SPRINT 1 COMPLETED (12 tasks, 5 files created)

   Ready to start SPRINT 2? (type 'continue')
> continue

â³ SPRINT 2: AUTHENTICATION - IN PROGRESS...
```

```bash
# Step-by-Step Mode
âœ… Task 1.1 complete: Database schema created

   Next: Task 1.2 - Set up migrations
   Continue? (waiting for your confirmation)
> yes

â³ Running Task 1.2...
```

---

## ğŸ”„ Model Hot-Swapping (NEW)

**Switch models mid-project** without losing context:

```bash
# Start with free model
> /models
  Selected: Gemini 2.0 Flash (free, fast)

# Work on your project...
ğŸ“‹ Roadmap generated, 15/45 tasks complete

# Hit rate limit? Switch instantly
> /models
  Selected: GPT-4 Turbo

âœ… Context preserved
âœ… Roadmap intact (15/45 tasks still tracked)
âœ… Continue from Task 16 seamlessly
```

**Supported mid-switch:**
- âœ… Full conversation history
- âœ… Roadmap progress
- âœ… Current sprint/task
- âœ… File changes tracking

---

## ğŸ› ï¸ Core Features

### Code Execution (Not Just Suggestions)
- âœ… **Read & analyze** entire codebases
- âœ… **Write files** - creates actual files, not just shows code
- âœ… **Edit files** - refactors existing code in place
- âœ… **Run commands** - npm install, pytest, build, deploy
- âœ… **Search** - glob patterns, grep content

### ğŸ  Local Models = True Freedom
- âœ… **Unlimited tokens** - No rate limits, no quotas
- âœ… **100% private** - Your code never leaves your machine
- âœ… **Zero cost** - Run Qwen, DeepSeek, Codestral locally via Ollama
- âœ… **Offline capable** - Work without internet after model download
- âœ… **Full control** - Switch between 6 local models instantly

### Smart Systems
- âœ… **Auto error recovery** - Module not found? Auto-installs
- âœ… **Undo/rollback** - `/undo` or `/undo 5` to revert changes
- âœ… **Session persistence** - Auto-saves every 5 messages
- âœ… **Git integration** - Natural language git commands

### Developer Experience
- âœ… **20+ AI models** - Local (Ollama) + Cloud (GPT/Claude/Gemini/Groq/xAI/DeepSeek)
- âœ… **Hardware detection** - Recommends best models for your system
- âœ… **Streaming responses** - See output in real-time
- âœ… **Context management** - Never forgets what you're building

---

## ğŸ“‹ Commands

### New Commands
```bash
/mode                  # View/change execution mode (unstoppable/sprint/step)
/roadmap               # View current project roadmap and progress
/models                # Switch models (context preserved!)
```

### Essential Commands
```bash
/help                  # Show all commands
/setup                 # Guided configuration wizard
/hardware              # Analyze system & model compatibility
/apikey <provider>     # Configure API keys
```

### Session & Undo
```bash
/sessions              # List saved sessions
/sessions load <id>    # Resume previous work
/undo [n]              # Undo last n operations
/snapshots             # View undo history
```

### Context Management
```bash
/context               # Show conversation stats
/clear                 # Clear conversation
/tools                 # List available tools
/exit                  # Exit CLI
```

---

## ğŸ¤– Supported Models (20+ Models)

### ğŸ  Local Models (Free - Runs on Your PC via Ollama)

**âœ¨ Benefits: Unlimited tokens â€¢ 100% private â€¢ Zero cost â€¢ Works offline**

| Model | Parameters | Context | Quality | RAM Required |
|-------|------------|---------|---------|--------------|
| Qwen 2.5 Coder 1.5B | 1.5B | 4K | â­â­â­ | 4GB+ |
| Qwen 2.5 Coder 7B | 7B | 8K | â­â­â­â­ | 8GB+ |
| Qwen 2.5 Coder 14B | 14B | 8K | â­â­â­â­ | 16GB+ |
| Qwen 2.5 Coder 32B | 32B | 16K | â­â­â­â­â­ | 32GB+ |
| DeepSeek Coder v2 16B | 16B | 16K | â­â­â­â­ | 16GB+ |
| Codestral 22B | 22B | 32K | â­â­â­â­â­ | 24GB+ |

### â˜ï¸ Cloud APIs

#### Free Tier Available âœ¨
| Provider | Model | Context | Speed | Quality |
|----------|-------|---------|-------|---------|
| **Google** | Gemini 2.0 Flash | 1M | âš¡âš¡âš¡ Instant | â­â­â­â­ |
| **Google** | Gemini 1.5 Pro | 2M | ğŸ’¨ Fast | â­â­â­â­â­ |
| **Groq** | Llama 3.3 70B | 8K | âš¡âš¡âš¡ Instant | â­â­â­â­ |
| **Groq** | Llama 3.1 8B (groq-fast) | 8K | âš¡âš¡âš¡ Instant | â­â­â­ |
| **Groq** | Qwen 2.5 32B (groq-qwen) | 32K | âš¡âš¡âš¡ Instant | â­â­â­â­ |

#### Premium APIs
| Provider | Model | Context | Cost | Quality |
|----------|-------|---------|------|---------|
| **OpenAI** | GPT-4 Turbo | 128K | $10-30/1M | â­â­â­â­â­ |
| **OpenAI** | GPT-3.5 Turbo | 16K | $0.5-1.5/1M | â­â­â­ |
| **OpenAI** | O1 Preview | 128K | $15-60/1M | â­â­â­â­â­ |
| **Anthropic** | Claude 3.5 Sonnet | 200K | $3-15/1M | â­â­â­â­â­ |
| **Anthropic** | Claude 3 Opus | 200K | $15-75/1M | â­â­â­â­â­ |
| **xAI** | Grok Beta | 128K | TBD | â­â­â­â­ |
| **xAI** | Grok 2 | 128K | TBD | â­â­â­â­â­ |
| **DeepSeek** | DeepSeek Coder | 16K | $0.14/1M ğŸ’° | â­â­â­â­ |
| **DeepSeek** | DeepSeek Chat | 16K | $0.14/1M ğŸ’° | â­â­â­â­ |

**ğŸ’¡ Pro Tip:** Start with **Gemini 2.0 Flash** (free, 1M context) or **Groq Llama** (free, instant), then switch to premium models only when needed.

---

## ğŸ¬ Real Examples

### Example 1: Full-Stack App (Unstoppable Mode)

```bash
> /mode unstoppable

> Create a task management SaaS:
  - React frontend with Tailwind
  - Node.js API with MongoDB
  - Auth with JWT
  - Real-time updates with Socket.io
  - Deploy to Vercel & Railway

ğŸ“‹ Roadmap generated: 6 sprints, 31 tasks, ~120 min

âš¡ EXECUTING IN UNSTOPPABLE MODE...

âœ… Sprint 1: Database Setup (5 tasks) - 8 min
âœ… Sprint 2: Authentication (6 tasks) - 15 min
âœ… Sprint 3: Task CRUD API (7 tasks) - 22 min
âœ… Sprint 4: Frontend Components (8 tasks) - 35 min
âœ… Sprint 5: Real-time Features (3 tasks) - 18 min
âœ… Sprint 6: Deployment (2 tasks) - 12 min

ğŸ‰ PROJECT COMPLETE!
   31/31 tasks âœ…
   42 files created
   Frontend: https://task-app.vercel.app
   API: https://task-api.railway.app
```

### Example 2: Learning Mode (Step-by-Step)

```bash
> /mode step-by-step

> Refactor my Express app to use TypeScript

ğŸ“‹ Roadmap: 4 sprints, 12 tasks

â³ Task 1.1: Install TypeScript dependencies

  â–¸ bash â†’ npm install -D typescript @types/node @types/express
  âœ“ Installed successfully

Task 1.1 complete. Next: Create tsconfig.json
Continue? (y/n)
> y

â³ Task 1.2: Create tsconfig.json...

# You control every step - perfect for learning
```

### Example 3: Model Switching Mid-Project

```bash
# Start with free tier
> /models
  Selected: Gemini 2.0 Flash

> Build a complex analytics dashboard

ğŸ“‹ Roadmap: 35 tasks
â³ Progress: 18/35 tasks complete...

# Gemini hits rate limit
âŒ Error: Quota exceeded

# Switch instantly
> /models
  Selected: Claude 3.5 Sonnet

âœ… Context & roadmap preserved
â³ Resuming: Task 19/35 - Data visualization components
```

---

## ğŸ”‘ Quick Setup

### Option 1: In-CLI Setup (Easiest)

```bash
awaitter-lite
> /setup

ğŸ”§ Configuration Wizard
  1. OpenAI (GPT-4)
  2. Anthropic (Claude)
  3. Google (Gemini) âœ¨ Free
  4. Groq âœ¨ Free

Select provider: 3
Enter API key: [paste your key]
âœ… Gemini configured and tested!
```

### Option 2: Environment Variables

```bash
export GOOGLE_API_KEY="AIza..."        # Free tier available
export GROQ_API_KEY="gsk_..."          # Free tier available
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
```

**Get free API keys:**
- [Gemini (Google)](https://makersuite.google.com/app/apikey) - Free tier âœ¨
- [Groq](https://console.groq.com) - Free tier âœ¨

---

## ğŸ’¡ Pro Tips

### 1. Use Roadmaps for Complex Tasks

```bash
# âŒ Vague request
> Make my app better

# âœ… Clear request that triggers roadmap
> Refactor my app to:
  - Use TypeScript
  - Add error handling
  - Implement caching
  - Add comprehensive tests
```

### 2. Choose the Right Mode

- **Quick prototype?** â†’ Unstoppable mode
- **Production code?** â†’ Sprint mode (review each phase)
- **Learning TypeScript?** â†’ Step-by-step mode

### 3. Leverage Free Models First

```bash
# Gemini 2.0 Flash = FREE + 1M context + fast
# Perfect for most tasks

# Only upgrade to GPT-4/Claude for:
# - Very complex reasoning
# - Mission-critical code
```

### 4. Never Fear Breaking Things

```bash
> Refactor everything to use hooks

# 50 files changed...
# Something looks wrong?

> /undo 50

âœ… All changes reverted instantly
```

---

## ğŸ—ï¸ Local LLM Setup (Ollama) - Recommended!

**Why local models?**
- ğŸš€ **Unlimited tokens** - Code all day without hitting rate limits
- ğŸ”’ **100% private** - Your code never leaves your machine
- ğŸ’° **Zero cost** - No API bills, ever
- ğŸŒ **Works offline** - Code on planes, trains, anywhere
- âš¡ **Full control** - No service outages or downtime

**Setup is SUPER simple (2 steps):**

```bash
# 1. Install Ollama (one-time, takes 2 minutes)
# Windows/Mac: Download from https://ollama.com/download
# Linux:
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Choose your model - Awaitter does the rest! ğŸ‰
aw --model qwen-7b

# ğŸ¯ What happens automatically:
# âœ… Awaitter detects if model is downloaded
# âœ… Asks "Download qwen2.5-coder:7b (4.7GB)? (y/n)"
# âœ… Downloads the model for you
# âœ… Starts coding immediately

# That's it! No manual ollama pull needed!
```

**Real example:**

```bash
$ aw --model qwen-7b

ğŸ”§ Setting up local model: qwen2.5-coder:7b

âœ“ Ollama installed
Checking if model is downloaded...

Model: qwen2.5-coder:7b
Download size: 4.7GB
Required VRAM: 8GB GPU
Quality: Good

Download this model now? (y/n): y

â†» Downloading qwen2.5-coder:7b... This may take several minutes
âœ“ Model qwen2.5-coder:7b downloaded successfully

âœ… Ready to code!
```

**Available local models:**

| Model | Size | RAM | Quality | Command |
|-------|------|-----|---------|---------|
| Qwen 2.5 Coder 1.5B | 986MB | 4GB | â­â­â­ | `aw --model qwen-1.5b` |
| Qwen 2.5 Coder 7B | 4.7GB | 8GB | â­â­â­â­ | `aw --model qwen-7b` |
| Qwen 2.5 Coder 14B | 9GB | 16GB | â­â­â­â­ | `aw --model qwen-14b` |
| Qwen 2.5 Coder 32B | 19GB | 32GB | â­â­â­â­â­ | `aw --model qwen-32b` |
| DeepSeek Coder v2 | 8.9GB | 16GB | â­â­â­â­ | `aw --model deepseek` |
| Codestral 22B | 12GB | 24GB | â­â­â­â­â­ | `aw --model codestral` |

**ğŸ’¡ Pro Tip:** Start with `qwen-7b` (4.7GB) - great balance of speed and quality. Awaitter handles the entire download and setup for you!

---

## ğŸ› Troubleshooting

### "Module not found" errors?
Awaitter auto-fixes these. Just let it run:

```bash
> Run the tests

âŒ Cannot find module 'jest'
â†» Installing jest automatically...
âœ… npm install jest successful
âœ… Tests running...
```

### Roadmap not generating?
Roadmaps trigger for **complex tasks**. Be specific:

```bash
# âŒ Too simple
> Add a button

# âœ… Triggers roadmap
> Create a user authentication system with:
  - Login/signup forms
  - JWT tokens
  - Protected routes
  - Password reset
```

### Model not working?
Check API key configuration:

```bash
> /models

# Shows âœ“ for configured models
# Shows âœ— for missing keys

# Configure instantly:
> /apikey google AIza...
```

---

## âš ï¸ Important Notes

### Roadmap Persistence
- âœ… Survives CLI restarts
- âœ… Survives model switches
- âœ… Survives computer reboots (with auto-saved sessions)
- âŒ Cleared with `/clear` command

### Model Switching
- âœ… Switch anytime without losing context
- âœ… Roadmap progress preserved
- âš ï¸ Different models = different code styles (be consistent for production)

### Execution Modes
Change modes mid-project:
```bash
# Start fast
> /mode unstoppable

# Need to review?
> /mode sprint

# Model will adapt immediately
```

---

## â˜• Support This Project

Awaitter Lite is **free and open source**. If it saves you hours of work, consider supporting development:

<div align="center">

[![Ko-fi](https://img.shields.io/badge/Ko--fi-Support%20Development-FF5E5B?style=for-the-badge&logo=ko-fi&logoColor=white)](https://ko-fi.com/novolabs)

</div>

**Your support helps us:**
- Add more AI models and integrations
- Improve roadmap generation algorithms
- Provide faster bug fixes and updates
- Create better documentation and examples

Every contribution, no matter how small, makes a huge difference. Thank you! ğŸ™

---

## ğŸ“„ License

MIT - Use freely in personal and commercial projects

---

## ğŸ¤ Contributing & Feedback

Found a bug? Have an idea? We'd love to hear from you!

**Report Issues:** [github.com/awaitter/awaitter-lite/issues](https://github.com/awaitter/awaitter-lite/issues)

**Feature Requests:** Tell us what you want to build!

---

<div align="center">

**Made with â¤ï¸ by [NovoLabs](https://github.com/awaitter)**

â­ Star on GitHub â€¢ ğŸ› Report Bugs â€¢ ğŸ’¡ Suggest Features â€¢ â˜• Buy us a Coffee

[GitHub](https://github.com/awaitter/awaitter-lite) â€¢ [npm](https://www.npmjs.com/package/awaitter-lite) â€¢ [Ko-fi](https://ko-fi.com/novolabs)

---

**Start building smarter, not harder.** ğŸš€

```bash
npm install -g awaitter-lite && awaitter-lite
```

</div>
