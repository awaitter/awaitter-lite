# Awaitter Lite

<div align="center">

**Multi-model AI coding assistant that ACTUALLY codes for you**

[![npm version](https://img.shields.io/npm/v/awaitter-lite.svg)](https://www.npmjs.com/package/awaitter-lite)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[Installation](#-installation) â€¢ [Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Commands](#-commands) â€¢ [Examples](#-examples)

</div>

---

## ğŸ¯ What is Awaitter Lite?

Awaitter Lite is a **powerful CLI that actually writes code for you**, not just gives you suggestions. It supports 17 different AI models from local (Ollama) to cloud (GPT-4, Claude, Gemini, Groq, and more).

### CLI Preview

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—            â”‚
â”‚  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—           â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•           â”‚
â”‚  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—           â”‚
â”‚  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘           â”‚
â”‚  â•šâ•â•  â•šâ•â• â•šâ•â•â•â•šâ•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•   â•šâ•â•      â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•           â”‚
â”‚                                                                              â”‚
â”‚  â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                                               â”‚
â”‚  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•      AI Coding Assistant                      â”‚
â”‚  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—        Multi-model LLM interface                â”‚
â”‚  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•                                                 â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                                               â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•šâ•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•                                               â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                              â”‚
â”‚  Available commands:                                                         â”‚
â”‚                                                                              â”‚
â”‚  /help       Show help                    /undo [n]     Undo last changes   â”‚
â”‚  /models     List and switch models       /sessions     Manage sessions     â”‚
â”‚  /hardware   Analyze system hardware      /snapshots    View undo history   â”‚
â”‚  /setup      Run configuration wizard     /tools        List available toolsâ”‚
â”‚  /exit       Exit                                                            â”‚
â”‚                                                                              â”‚
â”‚  Type a message to start...                                                 â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                              â”‚
â”‚  > Create a FastAPI server with authentication and PostgreSQL               â”‚
â”‚                                                                              â”‚
â”‚  ğŸ¤– Assistant                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ âš™ï¸  write â†’ backend/main.py                                        â”‚    â”‚
â”‚  â”‚ âš™ï¸  write â†’ backend/models.py                                      â”‚    â”‚
â”‚  â”‚ âš™ï¸  write â†’ backend/auth.py                                        â”‚    â”‚
â”‚  â”‚ âš™ï¸  write â†’ backend/database.py                                    â”‚    â”‚
â”‚  â”‚ âš™ï¸  write â†’ requirements.txt                                       â”‚    â”‚
â”‚  â”‚ âš™ï¸  bash â†’ python -m pip install -r requirements.txt              â”‚    â”‚
â”‚  â”‚ âš™ï¸  bash â†’ uvicorn main:app --reload                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  FastAPI server created and running at http://localhost:8000                â”‚
â”‚  âœ… 5 files created                                                          â”‚
â”‚  âœ… All dependencies installed                                               â”‚
â”‚  âœ… Server running with hot-reload                                           â”‚
â”‚                                                                              â”‚
â”‚  ğŸ“ Working: C:\projects\my-app  |  Model: gemini-2.0-flash  |  Msgs: 2    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Installation

```bash
# Install globally
npm install -g awaitter-lite

# Or use with npx (no install needed)
npx awaitter-lite
```

## ğŸ’» Quick Start

```bash
# Start in current directory
awaitter-lite
# or short alias
aw

# With specific model
awaitter-lite --model gpt4
awaitter-lite --model claude
awaitter-lite --model gemini
awaitter-lite --model local    # Ollama

# In specific directory
awaitter-lite --directory /path/to/project
```

## ğŸ› ï¸ Features

### Core Capabilities
- âœ… **Read files** - Analyze and understand code
- âœ… **Write files** - Create new files and projects
- âœ… **Edit files** - Refactor and modify existing code
- âœ… **Execute commands** - Run bash/shell commands
- âœ… **Search files** - Find files with glob patterns
- âœ… **Search content** - Grep through file contents

### ğŸ”§ Git Integration
Full git support built into the CLI - work with repositories naturally:
- âœ… **git_status** - Check repository status
- âœ… **git_diff** - View changes and diffs
- âœ… **git_commit** - Create commits with messages
- âœ… **git_branch** - Manage branches (create, switch, delete)
- âœ… **git_log** - View commit history

Just ask: *"Show git status"* or *"Create a commit with all changes"*

### â®ï¸ Undo/Rollback System
Never fear making mistakes - instant safety net:
- âœ… **Automatic snapshots** - Created before every file change
- âœ… **Instant rollback** - `/undo` or `/undo 3` to revert changes
- âœ… **History tracking** - Up to 50 snapshots retained
- âœ… **View history** - `/snapshots` shows all available undo points

### ğŸ’¾ Session Persistence
Never lose your work again:
- âœ… **Auto-save** - Conversations saved every 5 messages
- âœ… **Resume anytime** - `/sessions load <id>` to continue where you left off
- âœ… **Session history** - `/sessions` lists all saved conversations
- âœ… **Cross-session** - Work on multiple projects seamlessly

### ğŸ”„ Smart Error Recovery
Automatically fixes common errors - no manual intervention needed:
- âœ… **Module not found?** â†’ Auto runs `npm install` or `pip install`
- âœ… **Python not found?** â†’ Tries `python3`, `python -m pip` alternatives
- âœ… **Port in use?** â†’ Suggests solutions to free the port
- âœ… **Syntax errors?** â†’ Provides actionable fix suggestions
- âœ… **10+ error patterns** - Continuously learning and improving

### âœ… Automatic Test Generation
Quality assurance built-in:
- âœ… **Tests for every function** - Automatically generated with code
- âœ… **Auto-execution** - Tests run immediately after creation
- âœ… **Coverage** - Includes edge cases and error conditions
- âœ… **Multiple frameworks** - pytest, Jest, and more

### Model Support
- âœ… **17 models** across 7 providers
- âœ… **Local models** - Run Ollama models offline (Qwen, DeepSeek, Codestral)
- âœ… **Cloud APIs** - GPT-4, Claude, Gemini, Groq, xAI Grok, DeepSeek
- âœ… **Hardware detection** - Checks which models work on your system
- âœ… **Interactive benchmark** - Compare speed, quality, cost

### Developer Experience
- âœ… **Streaming responses** - Real-time output
- âœ… **Context management** - Full conversation history
- âœ… **Setup wizard** - Guided configuration
- âœ… **In-CLI API key management** - No config file editing

## ğŸ”§ Commands

### Essential Commands
```bash
/help              # Show all commands
/models            # Interactive model selector with benchmark
/hardware          # Analyze system specs and compatibility
/setup             # Run configuration wizard
/apikey <p> <key>  # Configure API keys
```

### NEW: Session Management
```bash
/sessions          # List all saved sessions
/sessions load <id># Resume a previous conversation
/sessions clear    # Delete all sessions
```

### NEW: Undo/Rollback
```bash
/undo              # Undo last operation
/undo 3            # Undo last 3 operations
/snapshots         # View undo history
```

### NEW: Git Integration
Just ask in natural language:
```bash
> Show git status
> Create a commit with message "Add authentication"
> Show me the diff of the last commit
> Create a new branch feature/login
> Show last 5 commits
```

### Context Management
```bash
/context           # Show conversation info
/clear             # Clear conversation
/save [file]       # Save conversation
/load <file>       # Load conversation
/tools             # List available tools
/exit              # Exit CLI
```

## ğŸ“ Examples

### 1. Create a Complete Project

```bash
> Create a FastAPI server with:
  - User authentication (JWT)
  - PostgreSQL database
  - CRUD endpoints for tasks
  - Tests with pytest
  - README with setup instructions
```

**What happens:**
- âœ… Creates all backend files
- âœ… Writes comprehensive tests
- âœ… Installs dependencies automatically
- âœ… Runs the server
- âœ… Creates snapshots for undo

### 2. Fix Errors Automatically

```bash
> Run npm test
```

**If error "Module 'jest' not found":**
```
âŒ Error: Cannot find module 'jest'
â†» Missing Node.js module: jest. Installing automatically...
âœ… npm install jest successful
âœ… Tests now passing (15/15)
```

### 3. Work with Git

```bash
> Show me what files changed

ğŸ¤– git_status executed:
  Modified:   src/auth.ts
  Modified:   src/database.ts
  Untracked:  src/middleware.ts

> Create a commit with these changes

ğŸ¤– git_commit executed:
âœ… Commit created: "Add authentication middleware"
  3 files changed, 145 insertions(+)
```

### 4. Undo Mistakes

```bash
> Refactor all components to use hooks

ğŸ¤– 15 files modified...

> Wait, undo that

/undo 15

âœ… Successfully undone 15 operations
Files restored: 15
  - src/components/Header.tsx
  - src/components/Login.tsx
  ...
```

### 5. Resume Previous Work

```bash
# Later, in a new session
awaitter-lite

> /sessions

ğŸ“š Saved Sessions

  ID                          Date                 Model           Messages
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  session_2025-01-15_10-30   1/15/25, 10:30 AM    gemini-flash    25
  session_2025-01-14_15-20   1/14/25, 3:20 PM     gpt4            12

> /sessions load session_2025-01-15_10-30

âœ… Session loaded
  Conversation history restored. Continue from where you left off.
```

## ğŸ“Š Model Benchmark (/models)

```bash
> /models
```

Shows interactive comparison:

```
ğŸ“Š Model Benchmark & Selection

  Model                  Speed        Quality      Context  Cost
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ  Local Models (Ollama)
  Qwen 1.5B              Varies       â­â­â­        4K       Free
  Qwen 7B                Varies       â­â­â­â­       8K       Free
  Qwen 32B               Varies       â­â­â­â­â­     16K      Free

ğŸ¤– OpenAI
  GPT-4 Turbo            ğŸ’¨ Fast      â­â­â­â­â­     128K     $10-30/1M  âœ“
  GPT-3.5 Turbo          ğŸš€ V.Fast    â­â­â­        16K      $0.5-1.5/1M âœ“

ğŸ§  Anthropic (Claude)
  Claude 3.5 Sonnet      ğŸ’¨ Fast      â­â­â­â­â­     200K     $3-15/1M   âœ“

ğŸ” Google (Gemini)
  Gemini 2.0 Flash       âš¡ Instant    â­â­â­â­       1M       Free       âœ“
  Gemini 1.5 Pro         ğŸ’¨ Fast      â­â­â­â­â­     2M       $1.25-5/1M âœ“

ğŸš€ Groq (Free & Fast!)
  Llama 3.3 70B          âš¡ Instant    â­â­â­â­       8K       Free       âœ“
  Llama 3.1 8B           âš¡ Instant    â­â­â­        8K       Free       âœ“

ğŸ’ DeepSeek (Cheapest!)
  DeepSeek Coder         ğŸ’¨ Fast      â­â­â­â­       16K      $0.14/1M   âœ“
```

**Legend:** âœ“ = API key configured, âœ— = API key missing

Use arrow keys to select, press Enter. The CLI will:
1. Show detailed specs
2. Prompt for API key if needed
3. Switch to that model
4. Set as default

## ğŸ”‘ API Keys

### Quick Setup (In-CLI)

```bash
# Inside the CLI
/setup              # Guided wizard

# Or configure directly
/apikey openai sk-...
/apikey anthropic sk-ant-...
/apikey google AIza...
/apikey groq gsk_...
```

### Environment Variables

```bash
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
export GOOGLE_API_KEY="AIza..."
export GROQ_API_KEY="gsk_..."
export XAI_API_KEY="xai-..."
export DEEPSEEK_API_KEY="sk-..."
```

## ğŸ  Local LLM (Ollama)

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull a model
ollama pull qwen2.5-coder:7b

# Start Ollama
ollama serve

# Use with Awaitter
awaitter-lite --model qwen-7b
```

## ğŸ–¥ï¸ Hardware Analysis

```bash
> /hardware
```

```
ğŸ–¥ï¸  Hardware Analysis

System Specifications:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OS:        Windows 11
CPU:       Intel Core i7-12700K
Cores:     12 cores
RAM:       32 GB (28 GB free)
GPU:       NVIDIA RTX 3080
VRAM:      10 GB

Model Compatibility:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Model              Status        Performance
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
qwen2.5-coder:1.5b âœ“ Excellent   âš¡ Fast
qwen2.5-coder:7b   âœ“ Excellent   ğŸš€ Fast
qwen2.5-coder:32b  âš  Acceptable  ğŸ¢ Slow
gpt-4-turbo        âœ“ Excellent   âš¡ Instant
```

## ğŸ“ Tips & Tricks

### 1. Always Have an Undo Plan
```bash
# Before major changes
/snapshots          # Check current snapshots
# Make changes
# If something goes wrong:
/undo               # Or /undo 5
```

### 2. Use Sessions for Long Tasks
```bash
# Sessions auto-save every 5 messages
# But you can manually save anytime:
/save important-refactor
# Resume later:
/load important-refactor
```

### 3. Leverage Git Integration
```bash
# Natural language git commands:
> Show what I changed today
> Commit these changes with a good message
> Create a feature branch for the new login
```

### 4. Let Error Recovery Work
```bash
# Don't panic on errors - the CLI auto-fixes:
> Run the tests
# If module missing â†’ auto installs
# If port busy â†’ suggests fix
# If python not found â†’ tries alternatives
```

### 5. Compare Models Before Choosing
```bash
# Use /models to see:
# - Which is fastest for your needs
# - Which is cheapest
# - Which has the largest context window
# Switch anytime with /models
```

## â˜• Support This Project

If Awaitter Lite saves you time and makes your development workflow easier, consider supporting its development!

<div align="center">

[![Ko-fi](https://img.shields.io/badge/Ko--fi-Support%20Development-FF5E5B?style=for-the-badge&logo=ko-fi&logoColor=white)](https://ko-fi.com/novolabs)

</div>

**Why support?**
- ğŸš€ Helps maintain and improve this free tool
- âœ¨ Enables new features and model integrations
- ğŸ› Faster bug fixes and updates
- ğŸ“š Better documentation and examples

Your support, no matter how small, makes a huge difference. Thank you! ğŸ™

## ğŸ“– Documentation

For detailed documentation, visit [awaitter.com](https://awaitter.com)

## ğŸ› Found a Bug or Have Feedback?

Awaitter Lite is actively maintained by **NovoLabs**. If you encounter issues or have suggestions:

**Report via GitHub Issues**: [github.com/novolabs/awaitter-lite/issues](https://github.com/novolabs/awaitter-lite/issues)

Please include:
- Clear description of the problem
- Steps to reproduce
- Your environment (OS, Node version, model used)

Your feedback helps make this tool better for everyone! ğŸ™

## ğŸ“„ License

MIT

---

<div align="center">

**Made with â¤ï¸ by [NovoLabs](https://github.com/novolabs)**

[ğŸ› Report Bug](https://github.com/novolabs/awaitter-lite/issues) â€¢ [ğŸ’¡ Request Feature](https://github.com/novolabs/awaitter-lite/issues) â€¢ [â˜• Support on Ko-fi](https://ko-fi.com/novolabs)

</div>
